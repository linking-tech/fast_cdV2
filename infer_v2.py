import torch
import numpy as np
import mujoco
import h5py
import os
import time
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
from tqdm import tqdm
import seaborn as sns 
from scipy.stats import gaussian_kde # ç”¨äº KDE å›¾
# ====================================================================
# I. MuJoCo ç¯å¢ƒåˆå§‹åŒ–ä¸ SDF è®¡ç®— (ç”¨äº Ground Truth åŸºå‡†æµ‹è¯•)
# å¿…é¡»å¤åˆ¶ generate_data_IK.py ä¸­çš„æ ¸å¿ƒé€»è¾‘æ¥è®¡ç®— SDF
# ====================================================================

# å…¨å±€å˜é‡å ä½ç¬¦ (å°†åœ¨åˆå§‹åŒ–å‡½æ•°ä¸­å¡«å……)
MUJOCO_ENV = {}

def initialize_mujoco_environment():
    """åˆå§‹åŒ– MuJoCo æ¨¡å‹ã€æ•°æ®å’Œ SDF è®¡ç®—æ‰€éœ€çš„å‚æ•°"""
    global MUJOCO_ENV
    
    # è·¯å¾„ä½¿ç”¨æ‚¨åœ¨ generate_data_IK.py ä¸­ä½¿ç”¨çš„è·¯å¾„
    xml_path = r"D:\fast_cdV2\model\universal_robots_ur10e\scene_with_spheres.xml" 
    if not os.path.exists(xml_path):
        print(f"Error: XML file not found at {xml_path}. Cannot perform MuJoCo benchmark.")
        return False

    model = mujoco.MjModel.from_xml_path(xml_path)
    data = mujoco.MjData(model)
    
    # 1. å…³èŠ‚ä¿¡æ¯
    joint_names = ["shoulder_pan_joint", "shoulder_lift_joint", "elbow_joint",
                   "wrist_1_joint", "wrist_2_joint", "wrist_3_joint"]
    joint_ids = [model.joint(jname).id for jname in joint_names]
    joint_qpos_addrs = [model.jnt_qposadr[jid] for jid in joint_ids]

    mujoco.mj_forward(model, data)
    
    # 2. éšœç¢ç‰©ä¿¡æ¯ (FIXED: ä½¿ç”¨ data.geom_xpos è·å–ä¸–ç•Œåæ ‡)
    obstacle_spheres = []
    for i in range(model.ngeom):
        if model.geom_type[i] == mujoco.mjtGeom.mjGEOM_SPHERE:
            pos = data.geom_xpos[i].copy()
            radius = model.geom_size[i][0]
            obstacle_spheres.append((pos, radius))

    ur10e_bodies = {"base", "shoulder_link", "upper_arm_link", "forearm_link", 
                    "wrist_1_link", "wrist_2_link", "wrist_3_link"}
    ur10e_body_ids = {model.body(name).id for name in ur10e_bodies}
    
    if not obstacle_spheres:
        print("Warning: No spherical obstacles found for benchmark!")

    MUJOCO_ENV = {
        "model": model,
        "data": data,
        "joint_qpos_addrs": joint_qpos_addrs,
        "obstacle_spheres": obstacle_spheres,
        "ur10e_body_ids": ur10e_body_ids
    }
    return True

def set_qpos_mujoco(q):
    """è®¾ç½®å…³èŠ‚ä½ç½®å¹¶æ›´æ–°è¿åŠ¨å­¦"""
    model = MUJOCO_ENV["model"]
    data = MUJOCO_ENV["data"]
    joint_qpos_addrs = MUJOCO_ENV["joint_qpos_addrs"]
    
    data.qpos[:] = 0
    for idx, addr in enumerate(joint_qpos_addrs):
        data.qpos[addr] = q[idx]
    mujoco.mj_forward(model, data)

def compute_sdf_mujoco(q):
    """è®¡ç®— Ground Truth SDF"""
    set_qpos_mujoco(q)
    
    model = MUJOCO_ENV["model"]
    data = MUJOCO_ENV["data"]
    obstacle_spheres = MUJOCO_ENV["obstacle_spheres"]
    ur10e_body_ids = MUJOCO_ENV["ur10e_body_ids"]
    
    min_dist = 10.0
    
    for gid in range(model.ngeom):
        if model.geom_type[gid] != mujoco.mjtGeom.mjGEOM_CAPSULE:
            continue
        
        body_id = model.geom_bodyid[gid]
        if body_id not in ur10e_body_ids:
            continue 
        
        gpos = data.geom_xpos[gid]
        gmat = data.geom_xmat[gid].reshape(3, 3)
        r_link = model.geom_size[gid][0]
        half_len = model.geom_size[gid][1]
        axis = gmat[:, 2] 
        
        p1 = gpos - half_len * axis
        p2 = gpos + half_len * axis
        ab = p2 - p1
        ab_sq = np.dot(ab, ab) + 1e-8

        for center, r_obs in obstacle_spheres:
            ap = center - p1
            t = np.dot(ap, ab) / ab_sq
            t = np.clip(t, 0.0, 1.0)
            
            closest_point_on_segment = p1 + t * ab
            
            dist = np.linalg.norm(center - closest_point_on_segment) - (r_link + r_obs)
            
            if dist < min_dist:
                min_dist = dist
                
    return min_dist


# ====================================================================
# II. æ•°æ®åŠ è½½ä¸æ¨¡å‹æ¨ç†
# ====================================================================

def load_dataset(hdf5_path):
    with h5py.File(hdf5_path, "r") as f:
        X = f["joint_configs"][:]
        y_true = f["sdf_values"][:].flatten()
    return X, y_true

def load_model(model_path):
    # TorchScript æ¨¡å‹å¯ä»¥ç›´æ¥åŠ è½½åˆ° CPU æˆ– GPUï¼Œä¸éœ€è¦å®šä¹‰ç±»ç»“æ„
    model = torch.jit.load(model_path)
    model.eval()
    return model

def predict_sdf(model, X):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model.to(device)
    
    X_t = torch.from_numpy(X).float().to(device)
    with torch.no_grad():
        # æ¨¡å‹çš„è¾“å‡ºæ˜¯ (N,) ç»´åº¦ï¼Œè€Œä¸æ˜¯ (N, 1)
        pred = model(X_t).cpu().numpy().flatten()
    return pred

# ====================================================================
# III. æŒ‡æ ‡è®¡ç®—ä¸ç»˜å›¾ (ä¸åŸ infer.py é€»è¾‘ä¸€è‡´)
# ====================================================================

def compute_metrics(pred, true, threshold=0.05):
    # Collision recall: true collision (true < 0) â†’ pred < threshold
    true_collision = true < 0
    pred_risky = pred < threshold
    recall = np.mean(pred_risky[true_collision]) if true_collision.sum() > 0 else 1.0

    # False positive rate: true safe (>0.2) â†’ pred < threshold
    true_safe = true > 0.2
    pred_risky = pred < threshold
    fp_rate = np.mean(pred_risky[true_safe]) if true_safe.sum() > 0 else 0.0

    # MAE near boundary
    near_boundary = (true >= -0.05) & (true <= 0.05)
    mae_boundary = np.mean(np.abs(pred[near_boundary] - true[near_boundary])) if near_boundary.any() else 0.0

    return {
        "recall": recall,
        "fp_rate": fp_rate,
        "mae_boundary": mae_boundary,
        "mean_error": np.mean(np.abs(pred - true)),
        "max_error": np.max(np.abs(pred - true))
    }

def plot_roc_curve(pred, true, save_path="plots/roc_curve.png"):
    y_true_binary = (true < 0).astype(int)
    y_pred_proba = -pred  # è´Ÿ SDF æ„å‘³ç€æ›´é«˜çš„é£é™©
    fpr, tpr, _ = roc_curve(y_true_binary, y_pred_proba)
    roc_auc = auc(fpr, tpr)

    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve for Collision Detection')
    plt.grid(True, alpha=0.3)
    plt.legend(loc="lower right")
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close() # å…³é—­å›¾å½¢ä»¥èŠ‚çœå†…å­˜

def plot_scatter(pred, true, save_path="plots/scatter_plot.png"):
    plt.figure(figsize=(8, 8))
    plt.scatter(true, pred, alpha=0.6, s=10, c='blue')
    
    # ç¡®ä¿ red line è¦†ç›–æ•°æ®èŒƒå›´
    min_val = min(true.min(), pred.min())
    max_val = max(true.max(), pred.max())
    if np.isnan(min_val) or np.isnan(max_val): 
         min_val = -0.6
         max_val = 0.6
    
    plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')
    plt.xlabel("Ground Truth SDF")
    plt.ylabel("Predicted SDF")
    plt.title("Scatter Plot: Predicted vs Ground Truth")
    plt.grid(True, alpha=0.3)
    plt.legend()
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
def plot_sdf_and_gradient_slice(model, X_test, y_true, joint_idx=1, n_points=500, save_path="plots/sdf_gradient_slice.png"):
    """
    ç»˜åˆ¶ SDF å€¼å’Œå…¶å…³äºå•ä¸ªå…³èŠ‚çš„æ¢¯åº¦åˆ‡ç‰‡å›¾ã€‚
    çµæ„Ÿæ¥æºï¼šLi et al. - 2024 (RDF) Fig. 3(b)
    """
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model.to(device)

    # 1. ç¡®å®šåˆ‡ç‰‡åŸºå‡† (ä½¿ç”¨ä¸€ä¸ªéšæœºçš„é…ç½®ä½œä¸ºåˆ‡ç‰‡å¹³é¢)
    base_idx = np.random.randint(len(X_test))
    base_q = X_test[base_idx].copy()
    
    # 2. å®šä¹‰æ‰«æèŒƒå›´
    q_scan = base_q.copy()
    # å‡è®¾å…³èŠ‚é™åˆ¶åœ¨ [-pi, pi] é™„è¿‘, è¿™é‡Œæˆ‘ä»¬æ‰«æä¸€ä¸ªåˆç†çš„èŒƒå›´
    scan_range = np.linspace(-np.pi, np.pi, n_points)
    
    X_slice = np.tile(base_q, (n_points, 1)).astype(np.float32)
    X_slice[:, joint_idx] = scan_range

    # 3. è®¡ç®—é¢„æµ‹ SDF å’Œæ¢¯åº¦
    X_t = torch.from_numpy(X_slice).float().to(device)
    X_t.requires_grad_(True)
    
    with torch.no_grad():
        y_pred_slice = model(X_t).cpu().numpy().flatten()
    
    # é‡æ–°å¯ç”¨æ¢¯åº¦ä»¥è®¡ç®—å¯¼æ•°
    y_pred_t_grad = model(X_t)
    
    # æˆ‘ä»¬åªå…³å¿ƒ SDF çš„å¹³å‡å€¼ï¼Œè€Œä¸æ˜¯æ¯ä¸ªæ ·æœ¬çš„ min(SDF)
    # è¿™é‡Œçš„æ¨¡å‹è¾“å‡ºæ˜¯ min(d_k(q,p_i))ï¼Œæˆ‘ä»¬å‡è®¾æ¨¡å‹å­¦ä¹ äº†ä¸€ä¸ªå¤åˆè·ç¦»å‡½æ•°
    # ä¸”æˆ‘ä»¬å¸Œæœ›çŸ¥é“è¿™ä¸ªå‡½æ•°ç›¸å¯¹äº q_j çš„å˜åŒ–
    
    # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬è®¡ç®—æ¯ä¸ªè¾“å‡ºç›¸å¯¹äº q_scan çš„æ¢¯åº¦ï¼Œç„¶åå–å¹³å‡æˆ–æœ€å°å€¼æ¢¯åº¦
    gradients_list = []
    for i in range(n_points):
        # è®¡ç®—å½“å‰ç‚¹çš„æ‰€æœ‰è¾“å‡ºå¯¹æ‰€æœ‰è¾“å…¥çš„æ¢¯åº¦
        # ç”±äº traced_model åªæœ‰ä¸€ä¸ªè¾“å‡ºï¼Œæˆ‘ä»¬ç›´æ¥è®¡ç®—è¯¥è¾“å‡ºå¯¹è¾“å…¥çš„æ¢¯åº¦
        grads_all = torch.autograd.grad(y_pred_t_grad[i], X_t, retain_graph=True, allow_unused=True)[0]
        # æå–å½“å‰å…³èŠ‚çš„æ¢¯åº¦å€¼
        gradients_list.append(grads_all[i, joint_idx].item())
    
    gradients = np.array(gradients_list)
    
    # 4. å¯è§†åŒ–
    fig, axes = plt.subplots(2, 1, figsize=(10, 8), sharex=True)
    
    # --- SDF æ›²çº¿ ---
    axes[0].plot(scan_range, y_pred_slice, label=f'Predicted SDF (q{joint_idx+1} Slice)', color='crimson', linewidth=2)
    
    # åœ¨åŸå§‹æ•°æ®ä¸­æ‰¾åˆ°æœ€æ¥è¿‘è¿™ä¸ªåˆ‡ç‰‡çš„çœŸå®å€¼è¿›è¡Œç»˜åˆ¶ (å¯é€‰ï¼Œä½†å¾ˆæœ‰æŒ‘æˆ˜æ€§)
    # å¯»æ‰¾çœŸå®å€¼æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå› ä¸ºæˆ‘ä»¬åˆ‡ç‰‡åœ¨ä¸€ä¸ªç‰¹å®šé«˜ç»´é…ç½®å‘¨å›´ï¼Œ
    # è€ŒçœŸå®å€¼æ•°æ®ç‚¹åœ¨æ•´ä¸ªé«˜ç»´ç©ºé—´ä¸­æ˜¯ç¨€ç–çš„ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åªç»˜åˆ¶é¢„æµ‹å€¼ã€‚
    
    axes[0].axhline(0, color='black', linestyle='--', linewidth=1, alpha=0.7)
    axes[0].set_title(f'SDF Value vs. Joint Angle $q_{{{joint_idx+1}}}$ (Slice at Fixed $q$)', fontsize=14)
    axes[0].set_ylabel('Predicted SDF Value', fontsize=12)
    axes[0].grid(True, alpha=0.3)
    
    # --- æ¢¯åº¦æ›²çº¿ ---
    axes[1].plot(scan_range, gradients, label=f'Predicted Gradient $\\partial SDF/\\partial q_{{{joint_idx+1}}}$', color='royalblue', linewidth=2)
    axes[1].axhline(0, color='black', linestyle='--', linewidth=1, alpha=0.7)
    axes[1].set_title(f'SDF Gradient vs. Joint Angle $q_{{{joint_idx+1}}}$ (Slice)', fontsize=14)
    axes[1].set_xlabel(f'Joint Angle $q_{{{joint_idx+1}}}$ (radians)', fontsize=12)
    axes[1].set_ylabel('SDF Gradient Value', fontsize=12)
    axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close(fig)
    
def plot_large_error_diff(pred, true, error_threshold=0.01, max_points=1000):
    """
    Filters and plots true vs predicted SDF values only for samples where the absolute error > threshold.
    Simulates the 'Error Curve' visualization requested by the user.
    """
    save_path=f"plots/large_error_diff_curve_{error_threshold}.png"
    absolute_error = np.abs(pred - true)
    
    # 1. Filter indices where error is large
    large_error_indices = np.where(absolute_error > error_threshold)[0]
    
    if len(large_error_indices) == 0:
        print(f"Warning: No samples found with absolute error > {error_threshold}. Skipping this plot.")
        return

    # 2. Sample a subset of these indices if there are too many points
    if len(large_error_indices) > max_points:
        # Randomly sample to avoid overly dense plot
        sample_indices = np.random.choice(large_error_indices, size=max_points, replace=False)
        subtitle = f" (Showing random {max_points} of {len(large_error_indices)} points where Error > {error_threshold})"
    else:
        sample_indices = large_error_indices
        subtitle = f" (Showing all {len(large_error_indices)} points where Error > {error_threshold})"

    # 3. Extract sampled data
    true_sampled = true[sample_indices]
    pred_sampled = pred[sample_indices]
    
    # Sort by Ground Truth value for a cleaner, monotonic curve-like visualization (helps simulate the look of the user's image)
    sort_indices = np.argsort(true_sampled)
    true_sampled = true_sampled[sort_indices]
    pred_sampled = pred_sampled[sort_indices]
    
    # 4. Plotting
    plt.figure(figsize=(12, 6))
    
    # Plotting True values as a reference line (sorted, should look like a curve)
    plt.plot(true_sampled, label='Ground Truth SDF', color='blue', linestyle='-', linewidth=1.5, alpha=0.7)
    
    # Plotting Predicted values (dotted or distinct line/points)
    plt.plot(pred_sampled, label='Predicted SDF', color='red', linestyle='--', linewidth=1.5, alpha=0.9)
    
    # Also plot the difference/error bars or shaded area if needed, but the two lines are usually enough for visual comparison
    
    plt.title(f'True vs. Predicted SDF for High-Error Samples{subtitle}', fontsize=14)
    plt.xlabel(f'Sample Index (Sorted by True SDF Value)', fontsize=12)
    plt.ylabel('SDF Value', fontsize=12)
    plt.axhline(0, color='gray', linestyle=':', linewidth=1, alpha=0.7)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()

def plot_error_and_value_distribution(pred, true, save_path_base="plots/"):
    """
    ç»˜åˆ¶é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„æ ¸å¯†åº¦ä¼°è®¡(KDE)å’Œç»å¯¹è¯¯å·®ç›´æ–¹å›¾ã€‚
    çµæ„Ÿæ¥æºï¼šZhu et al. - 2024 (SDF-SC) Fig. 3(a)
    """
    
    # 1. KDE Plot: Predicted vs Ground Truth SDF
    plt.figure(figsize=(10, 6))
    
    # ä½¿ç”¨ seaborn/matplotlib ç»˜åˆ¶ KDE
    sns.kdeplot(true, label='Ground Truth SDF', fill=True, alpha=.5, linewidth=1.5, color='green')
    sns.kdeplot(pred, label='Predicted SDF', fill=True, alpha=.5, linewidth=1.5, color='blue')
    
    plt.axvline(0, color='red', linestyle='--', linewidth=1.5, alpha=0.7, label='Collision Boundary')
    plt.title('Distribution of SDF Values (Kernel Density Estimation)', fontsize=14)
    plt.xlabel('SDF Value', fontsize=12)
    plt.ylabel('Density', fontsize=12)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(f"{save_path_base}sdf_kde_distribution.png", dpi=150, bbox_inches='tight')
    plt.close()

    # 2. Absolute Error Histogram
    absolute_error = np.abs(pred - true)
    
    plt.figure(figsize=(10, 6))
    
    # ç»˜åˆ¶ç›´æ–¹å›¾ï¼Œé™åˆ¶ X è½´ä»¥æ’é™¤æç«¯ç¦»ç¾¤å€¼
    max_err_plot = np.percentile(absolute_error, 99.5) 
    sns.histplot(absolute_error[absolute_error <= max_err_plot], bins=50, kde=True, 
                 color='orange', edgecolor='black', alpha=0.7)
    
    mean_err = np.mean(absolute_error)
    plt.axvline(mean_err, color='red', linestyle='-', linewidth=2, label=f'Mean Error: {mean_err:.4f}')
    
    plt.title('Distribution of Absolute Prediction Error', fontsize=14)
    plt.xlabel(f'Absolute Error |Predicted - True| (Capped at {max_err_plot:.4f})', fontsize=12)
    plt.ylabel('Frequency', fontsize=12)
    plt.legend()
    plt.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    plt.savefig(f"{save_path_base}abs_error_histogram.png", dpi=150, bbox_inches='tight')
    plt.close()

# ====================================================================
# IV. åŸºå‡†æµ‹è¯•å‡½æ•° (MLP vs. MuJoCo)
# ====================================================================

def benchmark_inference_speed(model, X, num_runs=1000):
    """æµ‹é‡ MLP æ¨¡å‹æ¨ç†é€Ÿåº¦ (å•æ ·æœ¬)"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸš€ Benchmarking MLP inference on device: {device}")

    model.to(device)
    
    times = []
    # é¢„çƒ­ (Warmup)
    dummy_input = torch.from_numpy(X[:1]).float().to(device)
    for _ in range(100):
         _ = model(dummy_input)
    if device == "cuda":
        torch.cuda.synchronize()

    # æ­£å¼è®¡æ—¶
    for _ in range(num_runs):
        X_t = torch.from_numpy(X[np.random.randint(len(X)):np.random.randint(len(X))+1]).float().to(device)
        
        start_event = torch.cuda.Event(enable_timing=True) if device == "cuda" else None
        end_event = torch.cuda.Event(enable_timing=True) if device == "cuda" else None

        if start_event is not None:
            start_event.record()
            with torch.no_grad():
                _ = model(X_t)
            end_event.record()
            torch.cuda.synchronize() 
            time_ms = start_event.elapsed_time(end_event)
            times.append(time_ms)
        else:
            start = time.time()
            with torch.no_grad():
                _ = model(X_t)
            end = time.time()
            times.append((end - start) * 1000)

    avg_time = np.mean(times)
    std_time = np.std(times)
    print(f"âœ… MLP Inference Speed: {avg_time:.4f} ms Â± {std_time:.4f} ms per sample")
    return avg_time

def benchmark_mujoco_sdf(X_test_subset, num_runs=100):
    """æµ‹é‡ MuJoCo SDF è®¡ç®—é€Ÿåº¦ (å•æ ·æœ¬, CPU)"""
    if not MUJOCO_ENV:
        print("âŒ MuJoCo environment not initialized. Skipping MuJoCo benchmark.")
        return 9999.0 # è¿”å›ä¸€ä¸ªå¤§å€¼

    print(f"ğŸš€ Benchmarking MuJoCo Ground Truth SDF calculation ({num_runs} samples)...")
    
    mujoco_times = []
    
    # é¢„çƒ­ (Warmup)
    for _ in range(10):
        _ = compute_sdf_mujoco(X_test_subset[0])

    # æ­£å¼è®¡æ—¶
    for i in tqdm(range(num_runs), desc="MuJoCo Timing"):
        q = X_test_subset[i % len(X_test_subset)]
        start = time.time()
        _ = compute_sdf_mujoco(q)
        end = time.time()
        mujoco_times.append((end - start) * 1000) # è½¬æ¢ä¸ºæ¯«ç§’

    avg_time = np.mean(mujoco_times)
    std_time = np.std(mujoco_times)
    print(f"âœ… MuJoCo SDF Time (CPU): {avg_time:.4f} ms Â± {std_time:.4f} ms per sample")
    return avg_time
def plot_trajectory_error_curve(y_pred, y_true, threshold=0.01, num_steps=200):
    """
    Plots the absolute prediction error over a mock sequential trajectory,
    highlighting points that exceed the specified error threshold.
    """
    
    # 1. Simulate a trajectory (use the first N points as time steps)
    N = len(y_pred)
    num_steps = min(N, num_steps)
    
    y_pred_traj = y_pred[:num_steps]
    y_true_traj = y_true[:num_steps]
    
    absolute_error = np.abs(y_pred_traj - y_true_traj)
    time_steps = np.arange(num_steps)
    
    # 2. Identify high-error points
    high_error_mask = absolute_error > threshold
    
    # 3. Visualization
    plt.figure(figsize=(10, 6))
    
    # Plot the full error curve (as background/context)
    plt.plot(time_steps, absolute_error, 
             label='Absolute Error $|y_{pred} - y_{true}|$', 
             color='gray', linewidth=1.5, alpha=0.7)
    
    # Plot the high error points (as scatter points, mirroring the user's image style)
    plt.scatter(time_steps[high_error_mask], absolute_error[high_error_mask], 
                label=f'Error > {threshold:.2f} (Count: {high_error_mask.sum()})', 
                color='red', s=20, zorder=5)
    
    # Plot the threshold line
    plt.axhline(threshold, color='crimson', linestyle='--', linewidth=1.5, 
                label=f'Error Threshold: {threshold:.2f}', zorder=3)
    
    plt.title(f'Absolute Prediction Error along a Mock Trajectory (Highlighting Error > {threshold:.2f})', fontsize=14)
    plt.xlabel('Time Step (Mock Trajectory Index)', fontsize=12)
    plt.ylabel('Absolute Error (SDF Value)', fontsize=12)
    plt.ylim(0, np.percentile(absolute_error, 99.8) * 1.1) # Set Y limit dynamically
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    save_path = "plots/error_over_trajectory_curve.png"
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    return save_path

# ====================================================================
# V. ä¸»å‡½æ•° (ä¿®æ”¹ç‚¹ï¼šæ›´æ–°æ¨¡å‹è·¯å¾„)
# ====================================================================

def main():
    # è·¯å¾„
    test_hdf5_path = "dataset/sdf_dataset_test.h5"
    # *** ä¿®æ”¹ç‚¹ï¼šæ›´æ–°ä¸ºæ–°çš„æ¨¡å‹æ–‡ä»¶å ***
    model_path = "models/fast_sdf_model_mixed.pt" 

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(test_hdf5_path):
        print(f"Error: Test dataset not found at {test_hdf5_path}. Please check data generation output.")
        return
    if not os.path.exists(model_path):
        print(f"Error: Model file not found at {model_path}. Please run train.py first.")
        # è¡¥å……ï¼šå¦‚æœæ–°æ¨¡å‹ä¸å­˜åœ¨ï¼Œä½†æ—§æ¨¡å‹å­˜åœ¨ï¼Œå¯ä»¥å°è¯•ä½¿ç”¨æ—§æ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œä»¥ä¾¿ç»§ç»­ç»˜å›¾å’Œè¯„ä¼°ã€‚
        old_model_path = "models/fast_sdf_model.pt"
        if os.path.exists(old_model_path):
            print(f"Warning: New model {model_path} not found. Using old model {old_model_path} instead.")
            model_path = old_model_path
        else:
             return

    # 1. åŠ è½½æ•°æ®å’Œæ¨¡å‹
    print("ğŸ” Loading dataset and model...")
    X_test, y_true = load_dataset(test_hdf5_path)
    print(f"Dataset loaded: {len(X_test)} test samples")

    model = load_model(model_path)

    # 2. æ¨ç†
    print("âš¡ Running MLP inference on test data...")
    y_pred = predict_sdf(model, X_test)

    # 3. æ€§èƒ½æŒ‡æ ‡
    metrics = compute_metrics(y_pred, y_true)
    print("\nğŸ“Š Model Performance Metrics:")
    for k, v in metrics.items():
        print(f"   {k}: {v:.4f}")

    # 4. å¯è§†åŒ–
    os.makedirs("plots", exist_ok=True)
    plot_roc_curve(y_pred, y_true)
    plot_scatter(y_pred, y_true)
    
    # --- æ–°å¢çš„å¯è§†åŒ– ---
    # 4a. SDF å€¼å’Œæ¢¯åº¦åˆ‡ç‰‡å›¾ (é€‰æ‹©ç¬¬ä¸€ä¸ªå…³èŠ‚ q1)
    if X_test.shape[1] > 0:
        plot_sdf_and_gradient_slice(model, X_test, y_true, joint_idx=0)
        print("âœ… SDF and Gradient Slice Plot saved to 'plots/' directory!")
    
    # 4b. åˆ†å¸ƒå›¾
    plot_error_and_value_distribution(y_pred, y_true)
   
    print("âœ… Distribution plots saved to 'plots/' directory!")
    # --- ç»“æŸæ–°å¢ ---
    
    print("\nâœ… ROC Curve and Scatter Plot saved to 'plots/' directory!")

    plot_large_error_diff(y_pred, y_true,error_threshold=0.01,max_points = 100000)
    plot_large_error_diff(y_pred, y_true,error_threshold=0.05,max_points = 100000)
    plot_large_error_diff(y_pred, y_true,error_threshold=0.1,max_points = 100000)

    print("\nâœ… Large error differences Plot saved to 'plots/' directory!")
    plot_trajectory_error_curve(y_pred, y_true,threshold=0.01)
    print("\nâœ… Large error CURVE Plot saved to 'plots/' directory!")
    # 5. é€Ÿåº¦åŸºå‡†æµ‹è¯• (MuJoCo vs. MLP)
    
    # MLP é€Ÿåº¦
    num_benchmark_samples = min(5000, len(X_test)) # é™åˆ¶æ ·æœ¬æ•°ä»¥åŠ é€Ÿæµ‹è¯•
    mlp_time_ms = benchmark_inference_speed(model, X_test, num_runs=num_benchmark_samples)

    # MuJoCo é€Ÿåº¦
    if initialize_mujoco_environment():
        mujoco_time_ms = benchmark_mujoco_sdf(X_test[:num_benchmark_samples], num_runs=num_benchmark_samples)
        
        print("\n=======================================================")
        print("           â±ï¸  ACCELERATION COMPARISON")
        print("=======================================================")
        print(f"MuJoCo SDF Time (CPU): {mujoco_time_ms:.4f} ms/sample")
        print(f"MLP Inference Time ({'GPU' if torch.cuda.is_available() else 'CPU'}): {mlp_time_ms:.4f} ms/sample")
        
        if mlp_time_ms > 0:
            speedup = mujoco_time_ms / mlp_time_ms
            print(f"ğŸš€ åŠ é€Ÿæ¯” (MuJoCo / MLP): {speedup:.2f}x")
        print("=======================================================")
        
    else:
        print("\nâŒ æ— æ³•è¿›è¡Œ MuJoCo åŸºå‡†æµ‹è¯•ï¼Œè¯·æ£€æŸ¥ XML æ–‡ä»¶è·¯å¾„ã€‚")


if __name__ == "__main__":
    # é…ç½® matplotlib ä½¿ç”¨éäº¤äº’å¼åç«¯ä»¥ç¡®ä¿åœ¨æ— æ˜¾ç¤ºç¯å¢ƒä¹Ÿèƒ½è¿è¡Œ
    plt.switch_backend('Agg')
    main()